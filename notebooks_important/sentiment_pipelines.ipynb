{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "RANDOM_STATE = 42\n",
    "COMPANY_REGEX = r'\".+\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MessageID</th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>DateAdded</th>\n",
       "      <th>DatePosted</th>\n",
       "      <th>MessageText</th>\n",
       "      <th>IsForward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>241407</td>\n",
       "      <td>1203560567</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-12 19:03:20</td>\n",
       "      <td>2023-05-12 19:02:42</td>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#SELG #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ –°–µ–ª–∏–≥–¥–∞—Ä: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 20...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33684</td>\n",
       "      <td>1136626166</td>\n",
       "      <td>230</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-03 20:56:29</td>\n",
       "      <td>2023-02-03 16:46:34</td>\n",
       "      <td>Ozon –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10090</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-06-02 19:18:37</td>\n",
       "      <td>2023-06-02 18:50:00</td>\n",
       "      <td>‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10090</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-06-02 19:18:37</td>\n",
       "      <td>2023-06-02 18:50:00</td>\n",
       "      <td>‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9826</td>\n",
       "      <td>1063908560</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-24 17:51:38</td>\n",
       "      <td>2023-04-24 13:54:00</td>\n",
       "      <td>‚Äã‚ÄãWindfall Tax ‚Äî –Ω–∞–ª–æ–≥ –Ω–∞ —Å–≤–µ—Ä—Ö–ø—Ä–∏–±—ã–ª—å. –ö–∞–∫–∏–µ ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MessageID   ChannelID  issuerid  SentimentScore           DateAdded  \\\n",
       "0     241407  1203560567       153               2 2023-05-12 19:03:20   \n",
       "1      33684  1136626166       230               4 2023-02-03 20:56:29   \n",
       "2      10090  1063908560       118               4 2023-06-02 19:18:37   \n",
       "3      10090  1063908560       220               5 2023-06-02 19:18:37   \n",
       "4       9826  1063908560        89               2 2023-04-24 17:51:38   \n",
       "\n",
       "           DatePosted                                        MessageText  \\\n",
       "0 2023-05-12 19:02:42  ‚ö†Ô∏èüá∑üá∫#SELG #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ –°–µ–ª–∏–≥–¥–∞—Ä: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 20...   \n",
       "1 2023-02-03 16:46:34  Ozon –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ...   \n",
       "2 2023-06-02 18:50:00  ‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...   \n",
       "3 2023-06-02 18:50:00  ‚Äã–§–æ–∫—É—Å—ã –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—èüî•–ê–∫—Ü–∏–∏ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏  üìà–í–¢–ë ...   \n",
       "4 2023-04-24 13:54:00  ‚Äã‚ÄãWindfall Tax ‚Äî –Ω–∞–ª–æ–≥ –Ω–∞ —Å–≤–µ—Ä—Ö–ø—Ä–∏–±—ã–ª—å. –ö–∞–∫–∏–µ ...   \n",
       "\n",
       "   IsForward  \n",
       "0      False  \n",
       "1      False  \n",
       "2      False  \n",
       "3      False  \n",
       "4      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/sentiment_texts.pickle')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å–Ω–æ–µ –¥–µ—Ä–µ–≤–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_mapper = pd.read_excel(DATA_PATH + f'/names and synonyms.xlsx', index_col='issuerid')\n",
    "synonyms_mapper['extended'] = synonyms_mapper['BGTicker'].apply(lambda x: x.split()[0] if not pd.isna(x) else x)\n",
    "\n",
    "synonyms_mapper['extended_2'] = synonyms_mapper['EMITENT_FULL_NAME'].apply(\n",
    "    lambda x: re.findall(COMPANY_REGEX, x)[0] if re.findall(COMPANY_REGEX, x) else None\n",
    ")\n",
    "synonyms_cols = ['EMITENT_FULL_NAME', 'VeryOddCompany', 'BGTicker', 'BGTicker.1',\n",
    "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
    "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'extended', 'extended_2']\n",
    "\n",
    "synonyms_list = synonyms_mapper[synonyms_cols].values\n",
    "synonyms_list = [[f'{synonym.strip()}' for synonym in synonyms_list if not pd.isna(synonym)] for synonyms_list in synonyms_list]\n",
    "\n",
    "keyword_dict = dict(zip(synonyms_mapper.index.values, synonyms_list))\n",
    "keyword_preprocessor = KeywordProcessor()\n",
    "keyword_preprocessor.add_keywords_from_dict(keyword_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9289/9289 [00:09<00:00, 934.39it/s] \n"
     ]
    }
   ],
   "source": [
    "df['mention'] = df['MessageText'].progress_apply(keyword_preprocessor.extract_keywords).apply(lambda x: list(set(x)))\n",
    "df['mention_predict'] = df.apply(lambda x: x['issuerid'] if x['issuerid'] in x['mention'] else 4242, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9656313003164485"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df['issuerid'], df['mention_predict'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(x, keyword_preprocessor):\n",
    "    text = x['MessageText']\n",
    "    if len(x['mention']) == 0:\n",
    "        return \n",
    "    if len(x['mention']) > 1:\n",
    "\n",
    "        if emoji.emoji_count(text) > 0:\n",
    "            texts = [s.strip() for s in re.split(r':[–∞-—è_]+:', emoji.demojize(text, language='ru')) if s.strip()]\n",
    "        else:\n",
    "            texts = nltk.sent_tokenize(text)\n",
    "        res = ' '.join([\n",
    "            txt for txt in texts \n",
    "            for mnt in keyword_preprocessor.extract_keywords(txt)\n",
    "            if mnt == x['issuerid'] \n",
    "        ])\n",
    "        return res\n",
    "    else: \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9289/9289 [00:24<00:00, 379.40it/s]\n"
     ]
    }
   ],
   "source": [
    "df['dataset'] = df.progress_apply(lambda x: prepare_dataset(x, keyword_preprocessor), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>SentimentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ö†Ô∏èüá∑üá∫#SELG #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ –°–µ–ª–∏–≥–¥–∞—Ä: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 20...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ozon –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ù–ú–¢–ü +3.9% –î–í–ú–ü +3.7% –ü–æ—Å–ª–µ —Ä–∞–∑—Ä—ã–≤–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLTR +3.6% –ë–ö–° –ú–ò –ø–∏—à–µ—Ç, —á—Ç–æ —Å—Ç–∞–≤–∫–∏ –∞—Ä–µ–Ω–¥—ã –ø–æ–ª...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>#FLOT #–î–∏–≤–∏–¥–µ–Ω–¥—ã üí∞ 7% ‚Äî –≤–æ–∑–º–æ–∂–Ω–∞—è –¥–∏–≤–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>üá∑üá∫#FLOT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ß–ò–°–¢–ê–Ø –ü–†–ò–ë–´–õ–¨ –°–û–í–ö–û–ú–§–õ–û–¢...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>–ï—Å—Ç—å –µ—â–µ –í–µ—á–Ω—ã–µ –ø–æ—Ä—Ç—Ñ–µ–ª–∏ (–Ω–∞–ø—Ä. –¢–∏–Ω—å–∫–æ—Ñ—Ñ), –≤ –∫...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>\"üí•üá∑üá∫#PLZL #–ª–∏—Å—Ç–∏–Ω–≥ #—Ç–æ—Ä–≥–∏  \"\"–ü–æ–ª—é—Å\"\" –≤–µ–¥–µ—Ç –¥–∏–∞...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>–†–æ—Å–Ω–µ—Ñ—Ç—å (ROSN) —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–∞—è —Ü–µ–Ω–∞ 425.17 —Ä—É–±–ª—è...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9289 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dataset  SentimentScore\n",
       "0     ‚ö†Ô∏èüá∑üá∫#SELG #–¥–∏–≤–∏–¥–µ–Ω–¥  —Å–¥ –°–µ–ª–∏–≥–¥–∞—Ä: –¥–∏–≤–∏–¥–µ–Ω–¥—ã 20...               2\n",
       "1     Ozon –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ...               4\n",
       "2     –ù–ú–¢–ü +3.9% –î–í–ú–ü +3.7% –ü–æ—Å–ª–µ —Ä–∞–∑—Ä—ã–≤–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ ...               4\n",
       "3     GLTR +3.6% –ë–ö–° –ú–ò –ø–∏—à–µ—Ç, —á—Ç–æ —Å—Ç–∞–≤–∫–∏ –∞—Ä–µ–Ω–¥—ã –ø–æ–ª...               5\n",
       "4                                                                     2\n",
       "...                                                 ...             ...\n",
       "9284  #FLOT #–î–∏–≤–∏–¥–µ–Ω–¥—ã üí∞ 7% ‚Äî –≤–æ–∑–º–æ–∂–Ω–∞—è –¥–∏–≤–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç...               4\n",
       "9285  üá∑üá∫#FLOT #–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å  –ß–ò–°–¢–ê–Ø –ü–†–ò–ë–´–õ–¨ –°–û–í–ö–û–ú–§–õ–û–¢...               4\n",
       "9286  –ï—Å—Ç—å –µ—â–µ –í–µ—á–Ω—ã–µ –ø–æ—Ä—Ç—Ñ–µ–ª–∏ (–Ω–∞–ø—Ä. –¢–∏–Ω—å–∫–æ—Ñ—Ñ), –≤ –∫...               3\n",
       "9287  \"üí•üá∑üá∫#PLZL #–ª–∏—Å—Ç–∏–Ω–≥ #—Ç–æ—Ä–≥–∏  \"\"–ü–æ–ª—é—Å\"\" –≤–µ–¥–µ—Ç –¥–∏–∞...               3\n",
       "9288  –†–æ—Å–Ω–µ—Ñ—Ç—å (ROSN) —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–∞—è —Ü–µ–Ω–∞ 425.17 —Ä—É–±–ª—è...               5\n",
       "\n",
       "[9289 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['dataset', 'SentimentScore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–±—É–µ–º dostoevsky + –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "model = FastTextSocialNetworkModel(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "# stop_words = [company.lower() for lst in keyword_dict.values() for company in lst]\n",
    "stop_words += list(punctuation)\n",
    "stop_words.remove('+')\n",
    "stop_words.remove('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8854, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df[['dataset', 'SentimentScore']]\n",
    "dataset = dataset[dataset['SentimentScore'] != 0]\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset[dataset['dataset'] != '']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(dataset['dataset'], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>skip</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>speech</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.615098</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>0.026769</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890304</td>\n",
       "      <td>0.071601</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.129413</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924152</td>\n",
       "      <td>0.065615</td>\n",
       "      <td>0.026769</td>\n",
       "      <td>0.160276</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622469</td>\n",
       "      <td>0.132974</td>\n",
       "      <td>0.144159</td>\n",
       "      <td>0.119213</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.743178</td>\n",
       "      <td>0.129413</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>0.187143</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neutral      skip  positive  negative    speech  target\n",
       "0  0.615098  0.287778  0.028446  0.026769  0.003183       2\n",
       "1  0.890304  0.071601  0.050341  0.129413  0.005070       4\n",
       "2  0.924152  0.065615  0.026769  0.160276  0.002900       4\n",
       "3  0.622469  0.132974  0.144159  0.119213  0.012064       5\n",
       "5  0.743178  0.129413  0.023699  0.187143  0.014967       2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, index=dataset.index)\n",
    "results_df['target'] = dataset['SentimentScore']\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.groupby(['SentimentScore']).count()['dataset'].plot(kind='bar', figsize=(12, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–±—É–µ–º TF-IDF + Stemming + SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8854/8854 [00:01<00:00, 5121.95it/s]\n"
     ]
    }
   ],
   "source": [
    "stem = SnowballStemmer('russian')\n",
    "dataset['stem'] = dataset['dataset'].progress_apply(stem.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6418622206867035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.63775971, 0.62782294, 0.62511292, 0.6097561 , 0.6395664 ,\n",
       "       0.6630533 , 0.6636528 , 0.6681736 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('text_preprocessing', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 4))),\n",
    "    ('classifier', LinearSVC(random_state=RANDOM_STATE, class_weight={1: 0, 2: 1.8, 3: 1.5, 4: 1, 5: 1.5}))\n",
    "])\n",
    "# scores = cross_val_score(pipe, dataset['dataset'], dataset['SentimentScore'], cv=6, scoring='accuracy')\n",
    "scores = cross_val_score(pipe, dataset['stem'], dataset['SentimentScore'], cv=8, scoring='accuracy')\n",
    "\n",
    "print(f'mean: {np.mean(scores)}')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–±—É–µ–º TF-IDF + SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.66      0.23      0.34       120\n",
      "           3       0.67      0.67      0.67       461\n",
      "           4       0.58      0.73      0.65       414\n",
      "           5       0.59      0.49      0.53        98\n",
      "\n",
      "    accuracy                           0.62      1107\n",
      "   macro avg       0.50      0.42      0.44      1107\n",
      "weighted avg       0.62      0.62      0.60      1107\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.66      0.31      0.42       154\n",
      "           3       0.65      0.61      0.63       418\n",
      "           4       0.62      0.80      0.70       444\n",
      "           5       0.67      0.60      0.63        87\n",
      "\n",
      "    accuracy                           0.64      1107\n",
      "   macro avg       0.52      0.46      0.48      1107\n",
      "weighted avg       0.64      0.64      0.63      1107\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.40      0.21      0.27        81\n",
      "           3       0.74      0.68      0.71       470\n",
      "           4       0.64      0.76      0.69       447\n",
      "           5       0.55      0.53      0.54       102\n",
      "\n",
      "    accuracy                           0.66      1107\n",
      "   macro avg       0.47      0.44      0.44      1107\n",
      "weighted avg       0.65      0.66      0.65      1107\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.43      0.27      0.33        97\n",
      "           3       0.62      0.69      0.65       389\n",
      "           4       0.66      0.70      0.68       497\n",
      "           5       0.63      0.46      0.53       115\n",
      "\n",
      "    accuracy                           0.63      1107\n",
      "   macro avg       0.47      0.42      0.44      1107\n",
      "weighted avg       0.62      0.63      0.62      1107\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.52      0.36      0.43       108\n",
      "           3       0.70      0.63      0.66       411\n",
      "           4       0.64      0.77      0.70       493\n",
      "           5       0.55      0.48      0.51        87\n",
      "\n",
      "    accuracy                           0.65      1107\n",
      "   macro avg       0.48      0.45      0.46      1107\n",
      "weighted avg       0.64      0.65      0.64      1107\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.67      0.37      0.48       127\n",
      "           3       0.68      0.66      0.67       404\n",
      "           4       0.65      0.77      0.70       481\n",
      "           5       0.61      0.53      0.57        86\n",
      "\n",
      "    accuracy                           0.66      1107\n",
      "   macro avg       0.52      0.47      0.48      1107\n",
      "weighted avg       0.65      0.66      0.65      1107\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.84      0.34      0.49       122\n",
      "           3       0.72      0.66      0.69       426\n",
      "           4       0.64      0.80      0.71       482\n",
      "           5       0.67      0.59      0.63        71\n",
      "\n",
      "    accuracy                           0.68      1106\n",
      "   macro avg       0.57      0.48      0.50      1106\n",
      "weighted avg       0.69      0.68      0.67      1106\n",
      "\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.60      0.35      0.45       116\n",
      "           3       0.70      0.66      0.68       405\n",
      "           4       0.69      0.79      0.73       509\n",
      "           5       0.61      0.59      0.60        74\n",
      "\n",
      "    accuracy                           0.68      1106\n",
      "   macro avg       0.52      0.48      0.49      1106\n",
      "weighted avg       0.68      0.68      0.67      1106\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6521412113608779"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 8\n",
    "kfold = KFold(folds)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(dataset['dataset'], dataset['SentimentScore']):\n",
    "    pipe = Pipeline([\n",
    "        ('text_preprocessing', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 4))),\n",
    "        ('classifier', LinearSVC(random_state=RANDOM_STATE, class_weight={1: 0, 2: 1.8, 3: 1.5, 4: 1, 5: 1.5}))\n",
    "    ])\n",
    "    X_train, y_train = dataset.iloc[train_idx]['dataset'], dataset.iloc[train_idx]['SentimentScore']\n",
    "    X_test, y_test = dataset.iloc[test_idx]['dataset'], dataset.iloc[test_idx]['SentimentScore']\n",
    "    pipe.fit(X_train, y_train)\n",
    "    accuracy_scores.append(pipe.score(X_test, y_test))\n",
    "    print(classification_report(y_test, pipe.predict(X_test)))\n",
    "    print('-' * 30)\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('text_preprocessing',\n",
       "                 TfidfVectorizer(ngram_range=(1, 4),\n",
       "                                 stop_words=['!', '\"', '#', '$', '%', '&', \"'\",\n",
       "                                             '(', ')', '*', ',', '.', '/', ':',\n",
       "                                             ';', '<', '=', '>', '?', '@', '[',\n",
       "                                             '\\\\', ']', '^', '_', '`', '{', '|',\n",
       "                                             '}', '~'])),\n",
       "                ('classifier',\n",
       "                 LinearSVC(class_weight={1: 0, 2: 1.8, 3: 1.5, 4: 1, 5: 1.5},\n",
       "                           random_state=42))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('text_preprocessing', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 4))),\n",
    "    ('classifier', LinearSVC(random_state=RANDOM_STATE, class_weight={1: 0, 2: 1.8, 3: 1.5, 4: 1, 5: 1.5}))\n",
    "])\n",
    "X_train, y_train = dataset['dataset'], dataset['SentimentScore']\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment.pkl', 'wb') as file:\n",
    "    pickle.dump(pipe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ner_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(keyword_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
